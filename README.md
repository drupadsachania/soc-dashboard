# ğŸ§­ Entropy â€” Epistemic AI Security System

*A centralized, uncertainty-aware SOC console for human-in-the-loop intelligence.*

---

## ğŸ” Overview

SOC Dashboard has evolved from a frontend-first SOC console into a **decision-support platform for epistemically aware security automation**.
It unifies dashboards, investigations, enrichment context, and AI-driven sense-making â€” while maintaining full analyst oversight and explainability.

The new architecture integrates **Large Language Models (LLMs)**, **Retrieval-Augmented Generation (RAG)**, and **agentic control loops** to ensure every recommendation is traceable, explainable, and uncertainty-aware.
Itâ€™s not just a tool for monitoring â€” itâ€™s a framework for *thinking clearly under pressure.*

---

## ğŸš€ Why This Exists

Modern security operations face **epistemic failure under scale**:

* Alerts multiply faster than they can be reasoned about
* Analysts reuse past conclusions as facts
* AI models generate confident but unverified narratives
* Systems reward closure over correctness

**SOC Dashboard: Epistemic Edition** is built to fix that â€” by exposing uncertainty instead of hiding it.

> â€œWeâ€™re not trying to be right faster.
> Weâ€™re trying to stay honest longer.â€

---

## ğŸ§© Core Principles

| âŒ We Refuse To                       | âœ… We Insist On                                            |
| ------------------------------------ | --------------------------------------------------------- |
| Let LLMs decide                      | LLMs generate *hypotheses*, not truth                     |
| Collapse uncertainty into confidence | Make uncertainty *observable and actionable*              |
| Automate irreversible actions        | Require explicit human or agentic approval                |
| Reward speed over honesty            | Reward traceability, explainability, and epistemic safety |
| Hide reasoning behind dashboards     | Expose reasoning trails in the open                       |

---

## ğŸ§  Key Features

### ğŸ§­ Centralized, Uncertainty-Aware Console

A single workspace that unifies alerts, enrichment, and epistemic reasoning:

* Context panels that display **contradictions and missing evidence**
* Real-time **hypothesis scoring** and **deferral tracking**
* Embedded documentation and rationale visualization

### ğŸ”„ Agentic Decision Loops

Implements a modern **OODA (Observeâ€“Orientâ€“Decideâ€“Act)** pattern:

* **Observe:** Collect telemetry from EDR, CTI, and SIEMs
* **Orient:** LLM-generated hypotheses normalized via RAG
* **Decide:** Specialized agents gate ACT / DEFER / ESCALATE
* **Act:** Human-reviewed, auditable, and reversible actions

### ğŸ§  RAG-Based Grounding

All AI reasoning is context-anchored using retrieval-augmented generation:

* Prevents hallucination through grounding and evidence scoring
* Introduces *Epistemic Uncertainty Index (EUI)* for every LLM output

### ğŸ“Š Observability by Design

Every model output, agent decision, and uncertainty signal is recorded:

* **Raw â†’ Normalized â†’ Scored â†’ Gated â†’ Acted** chain
* Structured observability for AI behavior and analyst review

### ğŸ§© Extensible Agent Framework

Tower-specific agents (Threat Intel, Incident Response, Uncertainty Control) handle domain workflows independently but cooperate through a shared decision bus.

---

## âš™ï¸ Architecture Overview

### High-Level Design

```
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â”‚                SOC Dashboard UI               â”‚
 â”‚             (React + Vite SPA)                â”‚
 â”‚----------------------------------------------â”‚
 â”‚  â€¢ Alerts, Enrichment, and Rationale Panels   â”‚
 â”‚  â€¢ Agent Decision Loop Visualization          â”‚
 â”‚  â€¢ Human-in-Loop Approvals                    â”‚
 â”‚  â€¢ Documentation Embedded in Context          â”‚
 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â”‚     AI Decision Support & Agent Layer        â”‚
 â”‚----------------------------------------------â”‚
 â”‚  â€¢ LLM Hypothesis Engine (Ollama)            â”‚
 â”‚  â€¢ Retrieval-Augmented Context (RAG)         â”‚
 â”‚  â€¢ Uncertainty Quantification Module          â”‚
 â”‚  â€¢ Domain Agents (Threat, CTI, IR)           â”‚
 â”‚  â€¢ Deferral & Escalation Logic               â”‚
 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â”‚          Integrations & Data Sources         â”‚
 â”‚----------------------------------------------â”‚
 â”‚  â€¢ SIEM / EDR / XDR                         â”‚
 â”‚  â€¢ Threat Intelligence APIs                  â”‚
 â”‚  â€¢ Observability & Audit Pipelines           â”‚
 â”‚  â€¢ Optional ML / Analytics Services          â”‚
 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ§ª Epistemic Metrics (in development)

| Metric                                   | Purpose                                                        |
| ---------------------------------------- | -------------------------------------------------------------- |
| **EUI â€” Epistemic Uncertainty Index**    | Quantifies contradiction, dispersion, and evidence sufficiency |
| **HSR â€” Hallucination Suppression Rate** | Measures false narrative mitigation                            |
| **DR â€” Deferral Ratio**                  | Tracks valid â€œI donâ€™t knowâ€ outcomes                           |
| **ATI â€” Analyst Trust Index**            | Captures user trust and explainability quality                 |

---

## ğŸ§° Tech Stack

**Frontend:** React + Vite
**Agent Framework:** LangGraph / Python services
**LLM Engine:** Ollama (local inference)
**RAG Layer:** Vectorized context embeddings
**Styling:** Token-driven design system (Figma â†’ React sync)
**Logging:** Structured observability with reasoning trails

---

## ğŸ§© Roadmap

**Phase 1 (Complete):** Control and Orientation correctness
**Phase 2 (In Progress):** RAG integration and uncertainty scoring
**Phase 3 (Planned):** Federated agent orchestration (FeRAG-style)
**Phase 4 (Planned):** Quantitative epistemic evaluation metrics

---

## ğŸ§‘â€ğŸ’» Who This Is For

* SOC analysts seeking clarity under complexity
* Security engineers designing human-first automation
* Researchers exploring epistemic uncertainty and explainable AI
* Anyone experimenting with **safe, grounded LLMs in security**

---

## ğŸ¤ Contributions

We welcome collaboration in:

* RAG + vector search optimization
* Agent orchestration and decision gating
* Uncertainty quantification
* UI visualization for epistemic metrics

> Pull requests that improve reasoning visibility or trust calibration are especially encouraged.

---

## ğŸ“œ License

MIT License

---

## ğŸ§­ Closing Note

**SOC Dashboard** has evolved from a SOC console into a platform for **epistemic integrity** in AI-driven security.
It doesnâ€™t promise certainty â€” it promises **clarity, traceability, and humility** in the face of uncertainty.

> *â€œThe goal isnâ€™t to eliminate doubt.
> Itâ€™s to make doubt work for you.â€*
